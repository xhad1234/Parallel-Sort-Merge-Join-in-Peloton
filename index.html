<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Parallel Sort Merge Join in Peloton by xhad1234</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Parallel Sort Merge Join in Peloton</h1>
      <h2 class="project-tagline">The Self-Driving Database Management System</h2>
      <a href="https://github.com/xhad1234/Parallel-Sort-Merge-Join-in-Peloton" class="btn">View on GitHub</a>
      <a href="https://github.com/xhad1234/Parallel-Sort-Merge-Join-in-Peloton/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/xhad1234/Parallel-Sort-Merge-Join-in-Peloton/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <p>Currently we are implementing the SIMD sort. Because it is independent from peloton, we put the current code in a different repository: <a href="https://github.com/sid1607/avx2-merge-sort">avx2-merge-sort</a></p>

<hr>

<h1>
<a id="proposal" class="anchor" href="#proposal" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Proposal</h1>

<h2>
<a id="summary" class="anchor" href="#summary" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Summary</h2>

<p>The objective is to implement the Sort-Merge Join operator into the Peloton in-memory database system made by <a href="https://github.com/cmu-db/peloton">CMUDB</a>. Recent database literature have designed various hardware-aware Sort-Merge join approaches that involve cache-conscious sorting mechanisms and NUMA-aware work decomposition schemes. We will incorporate these designs in the operator we build for Peloton and evaluate the performance gains and hardware utilization that these techniques have to offer.</p>

<h2>
<a id="background" class="anchor" href="#background" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Background</h2>

<p>Peloton is an in-memory database project that is developed by the CMU Database Group based on the RDBMS model with ACID guarantees. Since this system does not use the disk for storing and retrieving data, it needs to address bottlenecks associated with the memory hierarchy (caches), memory access patterns, concurrency control across multiple cores in order to utilize the available hardware effectively. Peloton, being a HTAP (Hybrid Transaction Processing) system, should be capable of handling both OLTP and OLAP workloads. OLAP involves long running queries that operate on large volumes of data across multiple relations. Joins are in important class of operators for OLAP workloads and OLAP joins have good scope for parallelization since they work on large volumes of data in memory. This approach to database parallelism is known as &gt; intra-query parallelism. Presently, Peloton does not support intra-query parallelism for any class of queries. Based on the relevance to what we learnt from this course and the approaches followed by existing database literature, we chose to work with sort-merge join.</p>

<p>A join algorithm accepts two input relations and merges corresponding tuples that match the predicate applied on the join attributes of the two relations. The classical Sort-Merge join algorithm consists of 3 phases - </p>

<ul>
<li><p>An optional partitioning phase - this phase is used to partition the input relations, which could be in the form of dividing the input load across different workers or cores.</p></li>
<li><p>The sort phase - this phase sorts the tuples of input relations based on the join key</p></li>
<li><p>The merge phase - this step scans through the sorted runs of the input relations in lock-step and merges a pair of tuples if the join predicate is satisfied. Assuming no duplicate tuples in either relation, merge can be performed in a single pass.</p></li>
</ul>

<p>The biggest challenger for parallelization is the sort phase since there are a lot of data dependencies in all sorting algorithms. The work done in Oracle and Intel's "Fast Join Implementation on Modern Multi-core CPUS" and  ETH's "new optimization and results for radix hash join" use a cache-conscious approach for the sort phase. These approaches implement merge sort and apply a different implementation for merge sort depending on the level in the memory hierarchy. For register-level and cache-level sorting, these papers claim that using SIMD is important to achieve good speedup and hardware efficiency. The work done in Hyper claims that SIMD-based sorting isn't necessary to achieve good performance and processor scalability for sort-merge join. They propose a NUMA-aware implementation that incurs the partitioning phase to chunk the input relations across NUMA-sockets, produces core-local sorted runs of these chunks and applies the join predicate for each chunk of the first relation against all chunks of the second relation. The rationale for this approach is that complete traversal of the second relation's chunks will not happen for any given first chunk, since they are already sorted. They also state that the memory prefetcher can mask the interconnect latency when sequential access is carried out on non-local sockets. Our project would be focussed towards integrating the key ideas introduced by these approaches - using a SIMD-based low-level sorting implementation and NUMA-aware data partitioning and evaluating the performance and scalability of our implementation as we add these features</p>

<h2>
<a id="the-challenge" class="anchor" href="#the-challenge" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>The Challenge</h2>

<p>We will be using AVX2 CPU intrinsics to implement cache-conscious sorting with SIMD. Since AVX2 offers low-level primitives it will be fairly complicated to implement a fully-functioning sorting network. We also need to be careful about the type of AVX2 instructions we use; an implementation with unnecessary calls to gather and scatter can limit the performance of the implementation. The workload involves two large relations that need to be sorted, which inherently comes with a high communication-to-computation ratio, since large tables will certainly not fit a single memory region. Since sorting is an operation that attempts to establish global order across distributed elements, reducing and optimization the communication patterns would be the primary challenge. None of the papers discussed in the previous section have a perfect solution for this. Instead, they rely on data access patterns and instructional similarity in some operations of join to make better utilization of the hardware.</p>

<h2>
<a id="resource" class="anchor" href="#resource" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Resource</h2>

<p>We are working based on the code base of  the CMU in-memory DBMS project Peloton. For SIMD merge-sort method, we plan to refer to the oracle and intel's sort merge work </p>

<p><code>C. Kim, T. Kaldewey, V. W. Lee, E. Sedlar, A. D. Nguyen, N. Satish, J. Chhugani, A. Di Blas,and P. Dubey.  Sort vs. hash revisited:  fast join implementation on modern multi-core cpus.Proceedings of the VLDB Endowment, 2(2):1378–1389, 2009.</code></p>

<p>For the numa-aware improvement, we plan to refer to the method provided by the Hyper work</p>

<p><code>M.-C.  Albutiu,  A.  Kemper,  and  T.  Neumann.   Massively  parallel  sort-merge  joins  in  mainmemory multi-core database systems.Proceedings of the VLDB Endowment, 5(10):1064–1075,201.</code></p>

<p>For the partitioning improvement, we plan to refer to the Radix Hash Join method</p>

<p><code>C.  Balkesen,  J.  Teubner,  G.  Alonso,  and  M.  T. ̈Ozsu.   Main-memory  hash  joins  on  multi-core cpus:  Tuning to the underlying hardware.  InData Engineering (ICDE), 2013 IEEE 29thInternational Conference on, pages 362–373. IEEE, 2013.</code></p>

<p>The parallel data lab provides PDL clusters for us to do the evaluation. There are nodes of NUMA architecture inside so as we can test the numa-aware implementation based on that.  Also, we plan to use TPC-h benchmark to compare the scalabilities among the non-paralel , non-NUMA-aware SIMD and NUMA-aware versions of peloton.</p>

<h2>
<a id="goal-and-deliverables" class="anchor" href="#goal-and-deliverables" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Goal and Deliverables</h2>

<ul>
<li><p>Minimum Goal: We set the minimum goal as the implementation of the logistic of the SIMD version merge-sort, together with a thorough performance analysis for that. We don't expect scalability for the minimum goal. The deliverable for this goal includes a consistent and runnable SIMD merge-join mechanism for peloton, and a report comparing and analysing of the performance among the sequential and parallel version. We expect a B score for reaching minimum goal. </p></li>
<li><p>Main Goal: The main goal is an scalable parallel merge-sort join mechanism of Peloton, together with the evaluation and performance analysis. Compared to minimum goal, we want to further optimize the method so as the performance of sort-merge join could scale when number of cores increase. The deliverable for this goal includes the scalable sort-merge join mechanism based on SIMD and an through evaluation report of that. We expect an A scrore for reaching main goal.</p></li>
<li><p>Stretch Goal: We have two stretch goals. The first stretch goal is to implement a NUMA-aware merge-sort join mechanism together with the evaluation showing the benefit gained from that. The second stretch goal is to implement the radix hash join partitioning method to get further performance improvement. The deliverable for this phase is the implementation together with an evaluation based on machine with NUMA architecture. We expect an A+ for accomplish either of the stretch goals.</p></li>
</ul>

<h2>
<a id="platform-choice" class="anchor" href="#platform-choice" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Platform Choice</h2>

<p>We use PDL cluster as the evaluation machine because it provides NUMA node. We choose C++ as the programming language since it has SIMD lib and it is the language of Peloton.</p>

<hr>

<h1>
<a id="project-checkpoint" class="anchor" href="#project-checkpoint" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Project Checkpoint</h1>

<h2>
<a id="revised-schedule" class="anchor" href="#revised-schedule" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Revised Schedule</h2>

<table>
<thead>
<tr>
<th>Week Number</th>
<th>Tasks</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>
<g-emoji alias="heavy_check_mark" fallback-src="https://assets-cdn.github.com/images/icons/emoji/unicode/2714.png" ios-version="6.0">✔️</g-emoji> Implement a sequential merge-sort join mechanism for Peloton</td>
</tr>
<tr>
<td>2</td>
<td>
<g-emoji alias="heavy_check_mark" fallback-src="https://assets-cdn.github.com/images/icons/emoji/unicode/2714.png" ios-version="6.0">✔️</g-emoji> Design and implement the SIMD version merge-sort</td>
</tr>
<tr>
<td>3</td>
<td>
<g-emoji alias="heavy_check_mark" fallback-src="https://assets-cdn.github.com/images/icons/emoji/unicode/2714.png" ios-version="6.0">✔️</g-emoji> Finish the SIMD version merge-sort</td>
</tr>
<tr>
<td></td>
<td>
<g-emoji alias="heavy_check_mark" fallback-src="https://assets-cdn.github.com/images/icons/emoji/unicode/2714.png" ios-version="6.0">✔️</g-emoji> Testing the SIMD version merge-sort</td>
</tr>
<tr>
<td>4-1</td>
<td>(Sid) Support sorting of all elements number</td>
</tr>
<tr>
<td></td>
<td>(Lei) Micro benchmark on Haswell Machine to compare std vs SIMD sort</td>
</tr>
<tr>
<td>4-2</td>
<td>(Sid) Explore 16*16 bitonic merge</td>
</tr>
<tr>
<td></td>
<td>(Lei) Compare with 4-fold network</td>
</tr>
<tr>
<td>5-1</td>
<td>(Sid) AVX2 compile with Peloton</td>
</tr>
<tr>
<td></td>
<td>(Lei) Merge the SIMD sort in Peloton</td>
</tr>
<tr>
<td>5-2</td>
<td>(Sid &amp; Lei) Figure out how to maintain the reference of tuple</td>
</tr>
<tr>
<td>6-1</td>
<td>(Sid &amp; Lei) Performance evaluation</td>
</tr>
<tr>
<td></td>
<td>(Sid &amp; Lei) Non-SIMD vs SIMD sort version in peloton</td>
</tr>
<tr>
<td>6-2</td>
<td>Prepare for the document and poster</td>
</tr>
</tbody>
</table>

<h2>
<a id="work-completed" class="anchor" href="#work-completed" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Work Completed</h2>

<h3>
<a id="sequential-merge-sort-join" class="anchor" href="#sequential-merge-sort-join" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Sequential Merge-Sort Join</h3>

<h3>
<a id="sorting-network" class="anchor" href="#sorting-network" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Sorting Network</h3>

<h3>
<a id="bitonic-sort" class="anchor" href="#bitonic-sort" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Bitonic Sort</h3>

<h2>
<a id="process" class="anchor" href="#process" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Process</h2>

<p>The process goes as the plan in proposal. By the end of week three, we have finished the minimum goal: implementation of the logistic of the SIMD version merge-sort. We are now focusing on expanding the functionality and conducting performance tests for our SIMD merge-sort. After that, we will deploy the merge sort in Peloton and reach our major goal. </p>

<h2>
<a id="poster-session-plan" class="anchor" href="#poster-session-plan" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Poster Session Plan</h2>

<p>We can show a simple demo by performing our merge-sort in peloton. In the meantime, we will use graph and charts to show   the performance of our implementation.</p>

<h2>
<a id="issues" class="anchor" href="#issues" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Issues</h2>

<p>List the issues that concern you the most. Are there any remaining unknowns (things you simply don't know how to solve, or resource you don't know how to get) or is it just a matter of coding and doing the work? If you do not wish to put this information on a public web site you are welcome to email the staff directly.</p>

<h2>
<a id="authors-and-contributors" class="anchor" href="#authors-and-contributors" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Authors and Contributors</h2>

<p>The project is planed to be done evenly by Siddharth Santurkar (<a href="https://github.com/sid1607" class="user-mention">@sid1607</a>) and Lei Qi (<a href="https://github.com/xhad1234" class="user-mention">@xhad1234</a>).</p>

<hr>

<hr>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/xhad1234/Parallel-Sort-Merge-Join-in-Peloton">Parallel Sort Merge Join in Peloton</a> is maintained by <a href="https://github.com/xhad1234">xhad1234</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
